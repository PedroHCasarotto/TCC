{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# PATH = f\"{os.getcwd()}/Documents/class/TCC\"\n",
    "\n",
    "df_fame_train = pd.read_csv('raw/signature_mol_train.csv').rename(columns={'cell_id': 'cell_line'})\n",
    "df_fame_test = pd.read_csv('raw/signature_mol_test.csv').rename(columns={'cell_id': 'cell_line'})\n",
    "df_fame_val = pd.read_csv('raw/signature_mol_val.csv').rename(columns={'cell_id': 'cell_line'})\n",
    "\n",
    "df_fame_train_cl = pd.read_csv('raw/signature_mol_train_cl.csv').rename(columns={'cell_id': 'cell_line'})\n",
    "df_fame_test_cl = pd.read_csv('raw/signature_mol_test_cl.csv').rename(columns={'cell_id': 'cell_line'})\n",
    "df_fame_val_cl = pd.read_csv('raw/signature_mol_val_cl.csv').rename(columns={'cell_id': 'cell_line'})\n",
    "\n",
    "\n",
    "df_fame = pd.concat([\n",
    "    df_fame_train,\n",
    "    df_fame_test,\n",
    "    df_fame_val\n",
    "])\n",
    "\n",
    "df_fame_cl = pd.concat([\n",
    "    df_fame_train_cl,\n",
    "    df_fame_test_cl,\n",
    "    df_fame_val_cl\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import selfies as sf\n",
    "\n",
    "def pre_processing_dataframe(dataset):\n",
    "    # Taking out repetitive molecules\n",
    "    counts = dataset.groupby(['cell_line', 'smiles']).size().reset_index(name='count')\n",
    "    molecules_to_use = pd.DataFrame(counts[counts['count'] == 1]).drop('count', axis=1)\n",
    "\n",
    "    dataset = dataset.merge(molecules_to_use, on=['smiles', 'cell_line'], how='inner')\n",
    "    \n",
    "    # Applying SELFIES\n",
    "    dataset['selfies'] = dataset.smiles.apply(lambda x: re.findall(r'\\[.*?\\]', sf.encoder(x)))\n",
    "    \n",
    "    # Formating gene_e\n",
    "    dataset['gene_e'] = dataset.gene_expression.apply(lambda x: '//'.join(f\"{float(num):.6f}\" for num in x[1:-1].split(', ')))\n",
    "\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fame = pre_processing_dataframe(df_fame)\n",
    "df_fame_cl = pre_processing_dataframe(df_fame_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def split_data_in_train_and_validation(df_fame_new, df_fame_test, target_proportion):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets while ensuring that:\n",
    "    1. `pert_iname` does not overlap between the training and test sets.\n",
    "    2. The `cell_line` distribution is maintained in both the training and test sets.\n",
    "    3. The test set contains approximately the target proportion of the data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_train: DataFrame containing the training data.\n",
    "    - df_test: DataFrame containing the test data.\n",
    "    - target_proportion: The proportion of data to allocate to the test set (default is 10%).\n",
    "\n",
    "    Returns:\n",
    "    - df_train_final: DataFrame for the final training set.\n",
    "    - df_test_final: DataFrame for the final test set.\n",
    "    \"\"\"\n",
    "    # Example DataFrame (replace with your actual data)\n",
    "    data = df_fame_new[~df_fame_new.smiles.isin(df_fame_test.smiles)]\n",
    "\n",
    "    # Parameters\n",
    "    total_rows = len(data)\n",
    "    test_target_count = int(total_rows * target_proportion)\n",
    "\n",
    "    # Step 1: Split `pert_iname` into test and train datasets\n",
    "    pert_inames = data['pert_iname'].unique()\n",
    "    np.random.shuffle(pert_inames)  # Shuffle `pert_iname` to ensure randomness\n",
    "\n",
    "    # Calculate how many `pert_iname` should go into the test set\n",
    "    test_pert_inames = pert_inames[:int(len(pert_inames) * target_proportion)]\n",
    "\n",
    "    # Step 2: Create test and train datasets based on `pert_iname`\n",
    "    df_fame_val = data[data['pert_iname'].isin(test_pert_inames)]\n",
    "    df_fame_train = data[~data['pert_iname'].isin(test_pert_inames)]\n",
    "\n",
    "    # Step 3: Proportionally split by `cell_line` to ensure the same `cell_line` distribution in both datasets\n",
    "    # First, calculate the proportions of each `cell_line` in the train data\n",
    "    cell_line_proportions = df_fame_train['cell_line'].value_counts(normalize=True)\n",
    "\n",
    "    # Now, for each `cell_line`, we will move the same proportion of rows to the test dataset\n",
    "    df_fame_train_final = pd.DataFrame()\n",
    "    df_fame_val_final = pd.DataFrame()\n",
    "\n",
    "    # Track the number of rows added to test data to maintain the target size\n",
    "    added_rows_count = len(df_fame_val)\n",
    "\n",
    "    for cell_line, _ in cell_line_proportions.items():\n",
    "        # Filter data by `cell_line`\n",
    "        cell_line_train = df_fame_train[df_fame_train['cell_line'] == cell_line]\n",
    "        \n",
    "        # Calculate how many rows should go to the test set based on the `cell_line` proportion\n",
    "        cell_line_test_count = int(len(cell_line_train) * target_proportion)\n",
    "        \n",
    "        if added_rows_count + cell_line_test_count <= test_target_count:\n",
    "            # Add rows to the test data\n",
    "            df_fame_val_final = pd.concat([df_fame_val_final, cell_line_train.head(cell_line_test_count)])\n",
    "            # Remove rows from the train data\n",
    "            df_fame_train_final = pd.concat([df_fame_train_final, cell_line_train.tail(len(cell_line_train) - cell_line_test_count)])\n",
    "            added_rows_count += cell_line_test_count\n",
    "        else:\n",
    "            # If adding the calculated number of rows exceeds the target size, add remaining rows to reach the target size\n",
    "            remaining_count = test_target_count - added_rows_count\n",
    "            df_fame_val_final = pd.concat([df_fame_val_final, cell_line_train.head(remaining_count)])\n",
    "            df_fame_train_final = pd.concat([df_fame_train_final, cell_line_train.tail(len(cell_line_train) - remaining_count)])\n",
    "            added_rows_count += remaining_count\n",
    "            break\n",
    "        \n",
    "    return df_fame_train, df_fame_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VCAP    0.113279\n",
       "MCF7    0.110645\n",
       "Name: cell_line, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fame_test = pd.concat([\n",
    "    df_fame[(\n",
    "        (df_fame['pert_iname'] == 'dexamethasone') |\n",
    "        (df_fame['pert_iname'] == 'testosterone') \n",
    "    )],\n",
    "])\n",
    "\n",
    "\n",
    "df_fame_train, df_fame_val = split_data_in_train_and_validation(df_fame, df_fame_test, target_proportion=0.10)\n",
    "\n",
    "df_fame_val.cell_line.value_counts() / df_fame_train.cell_line.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fame_test_cl = df_fame_cl.loc[df_fame_test.index.tolist()]\n",
    "df_fame_train_cl = df_fame_cl.loc[df_fame_train.index.tolist()]\n",
    "df_fame_val_cl = df_fame_cl.loc[df_fame_val.index.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fame_test.to_csv('process/df_fame_test.csv', index=False)\n",
    "df_fame_train.to_csv('process/df_fame_train.csv', index=False)\n",
    "df_fame_val.to_csv('process/df_fame_val.csv', index=False)\n",
    "\n",
    "df_fame_test_cl.to_csv('process/df_fame_test_cl.csv', index=False)\n",
    "df_fame_train_cl.to_csv('process/df_fame_train_cl.csv', index=False)\n",
    "df_fame_val_cl.to_csv('process/df_fame_val_cl.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TransGEM_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
